{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213f37a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Input\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import EQTransformer.core.EqT_utils\n",
    "from EQTransformer.core.trainer import _make_dir, _split, _make_callback, DataGenerator, _document_training\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "\n",
    "def user_trainer(input_hdf5=None,\n",
    "            input_csv=None,\n",
    "            output_name=None,                \n",
    "            input_dimention=(6000, 3),\n",
    "            cnn_blocks=5,\n",
    "            lstm_blocks=2,\n",
    "            padding='same',\n",
    "            activation = 'relu',            \n",
    "            drop_rate=0.1,\n",
    "            shuffle=True, \n",
    "            label_type='gaussian',\n",
    "            normalization_mode='std',\n",
    "            augmentation=True,\n",
    "            add_event_r=0.6,\n",
    "            shift_event_r=0.99,\n",
    "            add_noise_r=0.3, \n",
    "            drop_channel_r=0.5,\n",
    "            add_gap_r=0.2,\n",
    "            scale_amplitude_r=None,\n",
    "            pre_emphasis=False,                \n",
    "            loss_weights=[0.05, 0.40, 0.55],\n",
    "            loss_types=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'],\n",
    "            train_valid_test_split=[0.85, 0.05, 0.10],\n",
    "            mode='generator',\n",
    "            batch_size=200,\n",
    "            epochs=200, \n",
    "            monitor='val_loss',\n",
    "            patience=12,\n",
    "            multi_gpu=False,\n",
    "            number_of_gpus=4,\n",
    "            gpuid=None,\n",
    "            gpu_limit=None,\n",
    "            use_multiprocessing=True):\n",
    "\n",
    "    args = {\n",
    "    \"input_hdf5\": input_hdf5,\n",
    "    \"input_csv\": input_csv,\n",
    "    \"output_name\": output_name,\n",
    "    \"input_dimention\": input_dimention,\n",
    "    \"cnn_blocks\": cnn_blocks,\n",
    "    \"lstm_blocks\": lstm_blocks,\n",
    "    \"padding\": padding,\n",
    "    \"activation\": activation,\n",
    "    \"drop_rate\": drop_rate,\n",
    "    \"shuffle\": shuffle,\n",
    "    \"label_type\": label_type,\n",
    "    \"normalization_mode\": normalization_mode,\n",
    "    \"augmentation\": augmentation,\n",
    "    \"add_event_r\": add_event_r,\n",
    "    \"shift_event_r\": shift_event_r,\n",
    "    \"add_noise_r\": add_noise_r,\n",
    "    \"add_gap_r\": add_gap_r,\n",
    "    \"drop_channel_r\": drop_channel_r,\n",
    "    \"scale_amplitude_r\": scale_amplitude_r,\n",
    "    \"pre_emphasis\": pre_emphasis,\n",
    "    \"loss_weights\": loss_weights,\n",
    "    \"loss_types\": loss_types,\n",
    "    \"train_valid_test_split\": train_valid_test_split,\n",
    "    \"mode\": mode,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,\n",
    "    \"monitor\": monitor,\n",
    "    \"patience\": patience,           \n",
    "    \"multi_gpu\": multi_gpu,\n",
    "    \"number_of_gpus\": number_of_gpus,           \n",
    "    \"gpuid\": gpuid,\n",
    "    \"gpu_limit\": gpu_limit,\n",
    "    \"use_multiprocessing\": use_multiprocessing\n",
    "    }\n",
    "                       \n",
    "    def train(args):\n",
    "        \"\"\" \n",
    "        \n",
    "        Performs the training.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        args : dic\n",
    "            A dictionary object containing all of the input parameters. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        history: dic\n",
    "            Training history.  \n",
    "            \n",
    "        model: \n",
    "            Trained model.\n",
    "            \n",
    "        start_training: datetime\n",
    "            Training start time. \n",
    "            \n",
    "        end_training: datetime\n",
    "            Training end time. \n",
    "            \n",
    "        save_dir: str\n",
    "            Path to the output directory. \n",
    "            \n",
    "        save_models: str\n",
    "            Path to the folder for saveing the models.  \n",
    "            \n",
    "        training size: int\n",
    "            Number of training samples.\n",
    "            \n",
    "        validation size: int\n",
    "            Number of validation samples.  \n",
    "            \n",
    "        \"\"\"    \n",
    "\n",
    "        \n",
    "        save_dir, save_models=_make_dir(args['output_name'])\n",
    "        training, validation=_split(args, save_dir)\n",
    "        callbacks=_make_callback(args, save_models)\n",
    "        model=user_build_model(args)\n",
    "        \n",
    "        if args['gpuid']:           \n",
    "            os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(gpuid)\n",
    "            tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            config.gpu_options.per_process_gpu_memory_fraction = float(args['gpu_limit']) \n",
    "            K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "            \n",
    "        start_training = time.time()                  \n",
    "            \n",
    "        if args['mode'] == 'generator': \n",
    "            \n",
    "            params_training = {'file_name': str(args['input_hdf5']), \n",
    "                              'dim': args['input_dimention'][0],\n",
    "                              'batch_size': args['batch_size'],\n",
    "                              'n_channels': args['input_dimention'][-1],\n",
    "                              'shuffle': args['shuffle'],  \n",
    "                              'norm_mode': args['normalization_mode'],\n",
    "                              'label_type': args['label_type'],                          \n",
    "                              'augmentation': args['augmentation'],\n",
    "                              'add_event_r': args['add_event_r'], \n",
    "                              'add_gap_r': args['add_gap_r'],  \n",
    "                              'shift_event_r': args['shift_event_r'],                            \n",
    "                              'add_noise_r': args['add_noise_r'], \n",
    "                              'drop_channe_r': args['drop_channel_r'],\n",
    "                              'scale_amplitude_r': args['scale_amplitude_r'],\n",
    "                              'pre_emphasis': args['pre_emphasis']}    \n",
    "                        \n",
    "            params_validation = {'file_name': str(args['input_hdf5']),  \n",
    "                                 'dim': args['input_dimention'][0],\n",
    "                                 'batch_size': args['batch_size'],\n",
    "                                 'n_channels': args['input_dimention'][-1],\n",
    "                                 'shuffle': False,  \n",
    "                                 'norm_mode': args['normalization_mode'],\n",
    "                                 'augmentation': False}         \n",
    "\n",
    "            training_generator = DataGenerator(training, **params_training)\n",
    "            validation_generator = DataGenerator(validation, **params_validation) \n",
    "\n",
    "            print('Started training in generator mode ...') \n",
    "            history = model.fit_generator(generator=training_generator,\n",
    "                                          validation_data=validation_generator,\n",
    "                                          use_multiprocessing=args['use_multiprocessing'],\n",
    "                                          workers=multiprocessing.cpu_count(),    \n",
    "                                          callbacks=callbacks, \n",
    "                                          epochs=args['epochs'],\n",
    "                                          class_weight={0: 0.11, 1: 0.89})\n",
    "            \n",
    "        elif args['mode'] == 'preload': \n",
    "            X, y1, y2, y3 = data_reader(list_IDs=training+validation, \n",
    "                                       file_name=str(args['input_hdf5']), \n",
    "                                       dim=args['input_dimention'][0], \n",
    "                                       n_channels=args['input_dimention'][-1], \n",
    "                                       norm_mode=args['normalization_mode'],\n",
    "                                       augmentation=args['augmentation'],\n",
    "                                       add_event_r=args['add_event_r'],\n",
    "                                       add_gap_r=args['add_gap_r'], \n",
    "                                       shift_event_r=args['shift_event_r'], \n",
    "                                       add_noise_r=args['add_noise_r'],  \n",
    "                                       drop_channe_r=args['drop_channel_r'],\n",
    "                                       scale_amplitude_r=args['scale_amplitude_r'],\n",
    "                                       pre_emphasis=args['pre_emphasis'])\n",
    "             \n",
    "            print('Started training in preload mode ...', flush=True) \n",
    "            history = model.fit({'input': X}, \n",
    "                                {'detector': y1, 'picker_P': y2, 'picker_S': y3}, \n",
    "                                epochs=args['epochs'],\n",
    "                                validation_split=args['train_valid_test_split'][1],\n",
    "                                batch_size=args['batch_size'], \n",
    "                                callbacks=callbacks,\n",
    "                                class_weight={0: 0.11, 1: 0.89})            \n",
    "        else:\n",
    "            print('Please specify training_mode !', flush=True)\n",
    "        end_training = time.time()  \n",
    "        \n",
    "        return history, model, start_training, end_training, save_dir, save_models, len(training), len(validation)\n",
    "                  \n",
    "    history, model, start_training, end_training, save_dir, save_models, training_size, validation_size=train(args)  \n",
    "    _document_training(history, model, start_training, end_training, save_dir, save_models, training_size, validation_size, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c07d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################\n",
    "def user_encoder(filter_number, filter_size, depth, drop_rate, ker_regul, bias_regul, activation, padding, inpC):\n",
    "    ' Returns the encoder that is a combination of residual blocks and maxpooling.'        \n",
    "    e = inpC\n",
    "    for dp in range(depth):\n",
    "        e = Conv1D(filter_number[dp], \n",
    "                   filter_size[dp], \n",
    "                   padding = padding, \n",
    "                   activation = activation,\n",
    "                   kernel_regularizer = ker_regul,\n",
    "                   bias_regularizer = bias_regul,\n",
    "                   )(e)             \n",
    "        e = MaxPooling1D(3, padding = padding)(e)            \n",
    "    return(e) \n",
    "\n",
    "\n",
    "def user_decoder(filter_number, filter_size, depth, drop_rate, ker_regul, bias_regul, activation, padding, inpC):\n",
    "    ' Returns the dencoder that is a combination of residual blocks and upsampling. '           \n",
    "    d = inpC\n",
    "    for dp in range(depth):        \n",
    "        d = UpSampling1D(3)(d) \n",
    "        if dp < 2:\n",
    "            d = Cropping1D(cropping=(1, 1))(d)\n",
    "        elif dp == 2:\n",
    "            d = Cropping1D(cropping=(1, 0))(d)\n",
    "        d = Conv1D(filter_number[dp], \n",
    "                   filter_size[dp], \n",
    "                   padding = padding, \n",
    "                   activation = activation,\n",
    "                   kernel_regularizer = ker_regul,\n",
    "                   bias_regularizer = bias_regul,\n",
    "                   )(d)        \n",
    "    return(d)  \n",
    " #####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff9db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_encoder(filter_number, filter_size, depth, drop_rate, ker_regul, bias_regul, activation, padding, inpC):\n",
    "    ' Returns the encoder that is a combination of residual blocks and maxpooling.'        \n",
    "    e = inpC\n",
    "    for dp in range(depth):\n",
    "        e = keras.layers.SeparableConv1D(filter_number[dp], \n",
    "                   filter_size[dp], \n",
    "                   padding = padding, \n",
    "                   activation = activation,\n",
    "                   kernel_regularizer = ker_regul,\n",
    "                   bias_regularizer = bias_regul,\n",
    "                   )(e)             \n",
    "        e = MaxPooling1D(2, padding = padding)(e)            \n",
    "    return(e) \n",
    "\n",
    "\n",
    "def user_decoder(filter_number, filter_size, depth, drop_rate, ker_regul, bias_regul, activation, padding, inpC):\n",
    "    ' Returns the dencoder that is a combination of residual blocks and upsampling. '           \n",
    "    d = inpC\n",
    "    for dp in range(depth):        \n",
    "        d = UpSampling1D(2)(d) \n",
    "        if dp == 3:\n",
    "            d = Cropping1D(cropping=(1, 1))(d)           \n",
    "        d = keras.layers.SeparableConv1D(filter_number[dp], \n",
    "                   filter_size[dp], \n",
    "                   padding = padding, \n",
    "                   activation = activation,\n",
    "                   kernel_regularizer = ker_regul,\n",
    "                   bias_regularizer = bias_regul,\n",
    "                   )(d)        \n",
    "    return(d)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf34ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import add, Activation, LSTM, Conv1D\n",
    "from keras.layers import MaxPooling1D, UpSampling1D, Cropping1D, SpatialDropout1D, Bidirectional, BatchNormalization \n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import Adam\n",
    "from obspy.signal.trigger import trigger_onset\n",
    "import matplotlib\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "from EQTransformer.core.EqT_utils import _block_CNN_1, _block_BiLSTM, _transformer, _decoder, SeqSelfAttention, f1, _encoder,_lr_schedule\n",
    "\n",
    "class user_cred2():\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 nb_filters=[8, 16, 16, 32, 32, 96, 96, 128],\n",
    "                 kernel_size=[11, 9, 7, 7, 5, 5, 3, 3],\n",
    "                 padding='same',\n",
    "                 activationf='relu',\n",
    "                 endcoder_depth=4,\n",
    "                 decoder_depth=4,\n",
    "                 cnn_blocks=5,\n",
    "                 BiLSTM_blocks=3,\n",
    "                 drop_rate=0.1,\n",
    "                 loss_weights=[0.2, 0.3, 0.5],\n",
    "                 loss_types=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'],                                 \n",
    "                 kernel_regularizer=keras.regularizers.l1(1e-4),\n",
    "                 bias_regularizer=keras.regularizers.l1(1e-4),\n",
    "                 multi_gpu=False, \n",
    "                 gpu_number=4, \n",
    "                 ):\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.nb_filters = nb_filters\n",
    "        self.padding = padding\n",
    "        self.activationf = activationf\n",
    "        self.endcoder_depth= endcoder_depth\n",
    "        self.decoder_depth= decoder_depth\n",
    "        self.cnn_blocks= cnn_blocks\n",
    "        self.BiLSTM_blocks= BiLSTM_blocks     \n",
    "        self.drop_rate= drop_rate\n",
    "        self.loss_weights= loss_weights  \n",
    "        self.loss_types = loss_types       \n",
    "        self.kernel_regularizer = kernel_regularizer     \n",
    "        self.bias_regularizer = bias_regularizer \n",
    "        self.multi_gpu = multi_gpu\n",
    "        self.gpu_number = gpu_number\n",
    "\n",
    "        \n",
    "    def __call__(self, inp):\n",
    "\n",
    "        x = inp\n",
    "        x = user_encoder(self.nb_filters, \n",
    "                    self.kernel_size, \n",
    "                    self.endcoder_depth, \n",
    "                    self.drop_rate, \n",
    "                    self.kernel_regularizer, \n",
    "                    self.bias_regularizer,\n",
    "                    self.activationf, \n",
    "                    self.padding,\n",
    "                    x)    \n",
    "        #패딩한 데이터를 넘겨준다, encoder은 conv1d 7개짜리 sequence이다.\n",
    "        \n",
    "        for cb in range(self.cnn_blocks):\n",
    "\n",
    "            if cb > 2:\n",
    "                x = _block_CNN_1(self.nb_filters[7], 2, self.drop_rate, self.activationf, self.padding, x)\n",
    "            else:\n",
    "                x = _block_CNN_1(self.nb_filters[7], 3, self.drop_rate, self.activationf, self.padding, x)\n",
    "\n",
    "        for bb in range(self.BiLSTM_blocks):\n",
    "            x = _block_BiLSTM(self.nb_filters[1], self.drop_rate, self.padding, x)\n",
    "        #lstm커널\n",
    "            \n",
    "        x, weightdD0 = _transformer(self.drop_rate, None, 'attentionD0', x)             \n",
    "        encoded, weightdD = _transformer(self.drop_rate, None, 'attentionD', x)\n",
    "        #transformer 함수는 \n",
    "            \n",
    "        decoder_D = user_decoder([i for i in reversed(self.nb_filters)], \n",
    "                             [i for i in reversed(self.kernel_size)], \n",
    "                             self.decoder_depth, \n",
    "                             self.drop_rate, \n",
    "                             self.kernel_regularizer, \n",
    "                             self.bias_regularizer,\n",
    "                             self.activationf, \n",
    "                             self.padding,                             \n",
    "                             encoded)\n",
    "        #decoder은 7개짜리 upsampling sequence이다.\n",
    "        \n",
    "        d = Conv1D(1, 11, padding = self.padding, activation='sigmoid', name='detector')(decoder_D)\n",
    "\n",
    "\n",
    "        PLSTM = LSTM(self.nb_filters[1], return_sequences=True, dropout=self.drop_rate, recurrent_dropout=self.drop_rate)(encoded)\n",
    "        norm_layerP, weightdP = SeqSelfAttention(return_attention=True,\n",
    "                                                 attention_width= 3,\n",
    "                                                 name='attentionP')(PLSTM)\n",
    "        \n",
    "        decoder_P = user_decoder([i for i in reversed(self.nb_filters)], \n",
    "                            [i for i in reversed(self.kernel_size)], \n",
    "                            self.decoder_depth, \n",
    "                            self.drop_rate, \n",
    "                            self.kernel_regularizer, \n",
    "                            self.bias_regularizer,\n",
    "                            self.activationf, \n",
    "                            self.padding,                            \n",
    "                            norm_layerP)\n",
    "        \n",
    "        \n",
    "        P = Conv1D(1, 11, padding = self.padding, activation='sigmoid', name='picker_P')(decoder_P)\n",
    "        \n",
    "        SLSTM = LSTM(self.nb_filters[1], return_sequences=True, dropout=self.drop_rate, recurrent_dropout=self.drop_rate)(encoded) \n",
    "        norm_layerS, weightdS = SeqSelfAttention(return_attention=True,\n",
    "                                                 attention_width= 3,\n",
    "                                                 name='attentionS')(SLSTM)\n",
    "        \n",
    "        \n",
    "        decoder_S = user_decoder([i for i in reversed(self.nb_filters)], \n",
    "                            [i for i in reversed(self.kernel_size)],\n",
    "                            self.decoder_depth, \n",
    "                            self.drop_rate, \n",
    "                            self.kernel_regularizer, \n",
    "                            self.bias_regularizer,\n",
    "                            self.activationf, \n",
    "                            self.padding,                            \n",
    "                            norm_layerS) \n",
    "        \n",
    "        S = Conv1D(1, 11, padding = self.padding, activation='sigmoid', name='picker_S')(decoder_S)\n",
    "        \n",
    "\n",
    "        if self.multi_gpu == True:\n",
    "            parallel_model = Model(inputs=inp, outputs=[d, P, S])\n",
    "            model = multi_gpu_model(parallel_model, gpus=self.gpu_number)\n",
    "        else:\n",
    "            model = Model(inputs=inp, outputs=[d, P, S])\n",
    "\n",
    "        model.compile(loss=self.loss_types, loss_weights=self.loss_weights,    \n",
    "            optimizer=Adam(lr=_lr_schedule(0)), metrics=[f1])\n",
    "\n",
    "        return model\n",
    "#############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e5a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import add, Activation, LSTM, Conv1D\n",
    "from keras.layers import MaxPooling1D, UpSampling1D, Cropping1D, SpatialDropout1D, Bidirectional, BatchNormalization \n",
    "from keras.models import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import Adam\n",
    "from obspy.signal.trigger import trigger_onset\n",
    "import matplotlib\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "from EQTransformer.core.EqT_utils import _block_CNN_1, _block_BiLSTM, _transformer, _decoder, SeqSelfAttention, f1, _encoder,_lr_schedule\n",
    "\n",
    "class user_cred2():\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 nb_filters=[8, 16, 16, 32, 32, 96, 96, 128],\n",
    "                 kernel_size=[11, 9, 7, 7, 5, 5, 3, 3],\n",
    "                 padding='same',\n",
    "                 activationf='relu',\n",
    "                 endcoder_depth=7,\n",
    "                 decoder_depth=7,\n",
    "                 cnn_blocks=5,\n",
    "                 BiLSTM_blocks=3,\n",
    "                 drop_rate=0.1,\n",
    "                 loss_weights=[0.2, 0.3, 0.5],\n",
    "                 loss_types=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'],                                 \n",
    "                 kernel_regularizer=keras.regularizers.l1(1e-4),\n",
    "                 bias_regularizer=keras.regularizers.l1(1e-4),\n",
    "                 multi_gpu=False, \n",
    "                 gpu_number=4, \n",
    "                 ):\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.nb_filters = nb_filters\n",
    "        self.padding = padding\n",
    "        self.activationf = activationf\n",
    "        self.endcoder_depth= endcoder_depth\n",
    "        self.decoder_depth= decoder_depth\n",
    "        self.cnn_blocks= cnn_blocks\n",
    "        self.BiLSTM_blocks= BiLSTM_blocks     \n",
    "        self.drop_rate= drop_rate\n",
    "        self.loss_weights= loss_weights  \n",
    "        self.loss_types = loss_types       \n",
    "        self.kernel_regularizer = kernel_regularizer     \n",
    "        self.bias_regularizer = bias_regularizer \n",
    "        self.multi_gpu = multi_gpu\n",
    "        self.gpu_number = gpu_number\n",
    "\n",
    "        \n",
    "    def __call__(self, inp):\n",
    "\n",
    "        x = inp\n",
    "        x = user_encoder(self.nb_filters, \n",
    "                    self.kernel_size, \n",
    "                    self.endcoder_depth, \n",
    "                    self.drop_rate, \n",
    "                    self.kernel_regularizer, \n",
    "                    self.bias_regularizer,\n",
    "                    self.activationf, \n",
    "                    self.padding,\n",
    "                    x)    \n",
    "        #패딩한 데이터를 넘겨준다, encoder은 conv1d 7개짜리 sequence이다.\n",
    "        \n",
    "        for cb in range(self.cnn_blocks):\n",
    "            x = _block_CNN_1(self.nb_filters[6], 3, self.drop_rate, self.activationf, self.padding, x)\n",
    "            if cb > 2:\n",
    "                x = _block_CNN_1(self.nb_filters[6], 2, self.drop_rate, self.activationf, self.padding, x)\n",
    "        #cnn커널\n",
    "        for bb in range(self.BiLSTM_blocks):\n",
    "            x = _block_BiLSTM(self.nb_filters[1], self.drop_rate, self.padding, x)\n",
    "        #lstm커널\n",
    "            \n",
    "        x, weightdD0 = _transformer(self.drop_rate, None, 'attentionD0', x)             \n",
    "        encoded, weightdD = _transformer(self.drop_rate, None, 'attentionD', x)\n",
    "        #transformer 함수는 \n",
    "            \n",
    "        decoder_D = user_decoder([i for i in reversed(self.nb_filters)], \n",
    "                             [i for i in reversed(self.kernel_size)], \n",
    "                             self.decoder_depth, \n",
    "                             self.drop_rate, \n",
    "                             self.kernel_regularizer, \n",
    "                             self.bias_regularizer,\n",
    "                             self.activationf, \n",
    "                             self.padding,                             \n",
    "                             encoded)\n",
    "        #decoder은 7개짜리 upsampling sequence이다.\n",
    "        \n",
    "        d = Conv1D(1, 11, padding = self.padding, activation='sigmoid', name='detector')(decoder_D)\n",
    "\n",
    "\n",
    "        PLSTM = LSTM(self.nb_filters[1], return_sequences=True, dropout=self.drop_rate, recurrent_dropout=self.drop_rate)(encoded)\n",
    "        norm_layerP, weightdP = SeqSelfAttention(return_attention=True,\n",
    "                                                 attention_width= 3,\n",
    "                                                 name='attentionP')(PLSTM)\n",
    "        \n",
    "        decoder_P = user_decoder([i for i in reversed(self.nb_filters)], \n",
    "                            [i for i in reversed(self.kernel_size)], \n",
    "                            self.decoder_depth, \n",
    "                            self.drop_rate, \n",
    "                            self.kernel_regularizer, \n",
    "                            self.bias_regularizer,\n",
    "                            self.activationf, \n",
    "                            self.padding,                            \n",
    "                            norm_layerP)\n",
    "        \n",
    "        \n",
    "        P = Conv1D(1, 11, padding = self.padding, activation='sigmoid', name='picker_P')(decoder_P)\n",
    "        \n",
    "        SLSTM = LSTM(self.nb_filters[1], return_sequences=True, dropout=self.drop_rate, recurrent_dropout=self.drop_rate)(encoded) \n",
    "        norm_layerS, weightdS = SeqSelfAttention(return_attention=True,\n",
    "                                                 attention_width= 3,\n",
    "                                                 name='attentionS')(SLSTM)\n",
    "        \n",
    "        \n",
    "        decoder_S = user_decoder([i for i in reversed(self.nb_filters)], \n",
    "                            [i for i in reversed(self.kernel_size)],\n",
    "                            self.decoder_depth, \n",
    "                            self.drop_rate, \n",
    "                            self.kernel_regularizer, \n",
    "                            self.bias_regularizer,\n",
    "                            self.activationf, \n",
    "                            self.padding,                            \n",
    "                            norm_layerS) \n",
    "        \n",
    "        S = Conv1D(1, 11, padding = self.padding, activation='sigmoid', name='picker_S')(decoder_S)\n",
    "        \n",
    "\n",
    "        if self.multi_gpu == True:\n",
    "            parallel_model = Model(inputs=inp, outputs=[d, P, S])\n",
    "            model = multi_gpu_model(parallel_model, gpus=self.gpu_number)\n",
    "        else:\n",
    "            model = Model(inputs=inp, outputs=[d, P, S])\n",
    "\n",
    "        model.compile(loss=self.loss_types, loss_weights=self.loss_weights,    \n",
    "            optimizer=Adam(lr=_lr_schedule(0)), metrics=[f1])\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dbb45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "def user_build_model(args): \n",
    "\n",
    "    inp = Input(shape=args['input_dimention'], name='input') \n",
    "    model = user_cred2(nb_filters=[9, 18, 18, 54, 9,18, 18, 54],\n",
    "              kernel_size=[11, 9, 7, 7, 5, 5, 3],\n",
    "              padding=args['padding'],\n",
    "              activationf =args['activation'],\n",
    "              cnn_blocks=args['cnn_blocks'],\n",
    "              BiLSTM_blocks=args['lstm_blocks'],\n",
    "              drop_rate=args['drop_rate'], \n",
    "              loss_weights=args['loss_weights'],\n",
    "              loss_types=args['loss_types'],\n",
    "              kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "              bias_regularizer=keras.regularizers.l1(1e-4),\n",
    "              multi_gpu=args['multi_gpu'], \n",
    "              gpu_number=args['number_of_gpus'],  \n",
    "               )(inp)  \n",
    "    model.summary()  \n",
    "    return model\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d3d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_build_model(args): \n",
    "\n",
    "    inp = Input(shape=args['input_dimention'], name='input') \n",
    "    model = user_cred2(nb_filters=[8, 16, 16, 32, 32, 64, 32],\n",
    "              kernel_size=[11, 9, 7, 7, 5, 5, 3],\n",
    "              padding=args['padding'],\n",
    "              activationf =args['activation'],\n",
    "              cnn_blocks=args['cnn_blocks'],\n",
    "              BiLSTM_blocks=args['lstm_blocks'],\n",
    "              drop_rate=args['drop_rate'], \n",
    "              loss_weights=args['loss_weights'],\n",
    "              loss_types=args['loss_types'],\n",
    "              kernel_regularizer=keras.regularizers.l2(1e-6),\n",
    "              bias_regularizer=keras.regularizers.l1(1e-4),\n",
    "              multi_gpu=args['multi_gpu'], \n",
    "              gpu_number=args['number_of_gpus'],  \n",
    "               )(inp)  \n",
    "    model.summary()  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018fdde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 6000, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_29 (SeparableC (None, 6000, 8)      65          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 3000, 8)      0           separable_conv1d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_30 (SeparableC (None, 3000, 16)     216         max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1500, 16)     0           separable_conv1d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_31 (SeparableC (None, 1500, 16)     384         max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 750, 16)      0           separable_conv1d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_32 (SeparableC (None, 750, 32)      656         max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 375, 32)      0           separable_conv1d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_33 (SeparableC (None, 375, 32)      1216        max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 188, 32)      0           separable_conv1d_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_34 (SeparableC (None, 188, 64)      2272        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 94, 64)       0           separable_conv1d_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_35 (SeparableC (None, 94, 32)       2272        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 47, 32)       0           separable_conv1d_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 47, 32)       128         max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 47, 32)       0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 47, 32)       0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 47, 32)       128         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 47, 32)       0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, 47, 32)       0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 47, 32)       0           max_pooling1d_14[0][0]           \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 47, 32)       128         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 47, 32)       0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDr (None, 47, 32)       0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 47, 32)       128         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 47, 32)       0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, 47, 32)       0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 47, 32)       0           add_12[0][0]                     \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 47, 32)       128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 47, 32)       0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, 47, 32)       0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 47, 32)       128         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 47, 32)       0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 47, 32)       0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 47, 32)       0           add_13[0][0]                     \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 47, 32)       128         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 47, 32)       0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_21 (SpatialDr (None, 47, 32)       0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 47, 32)       128         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 47, 32)       0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_22 (SpatialDr (None, 47, 32)       0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 47, 32)       0           add_14[0][0]                     \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 47, 32)       128         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 47, 32)       0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_23 (SpatialDr (None, 47, 32)       0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 47, 32)       2080        spatial_dropout1d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 47, 32)       128         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 47, 32)       0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 47, 32)       0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 47, 32)       2080        spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 47, 32)       0           add_15[0][0]                     \n",
      "                                                                 conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 47, 32)       128         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 47, 32)       0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 47, 32)       0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 47, 32)       128         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 47, 32)       0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 47, 32)       0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 47, 32)       3104        spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 47, 32)       0           add_16[0][0]                     \n",
      "                                                                 conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 47, 32)       128         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 47, 32)       0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 47, 32)       0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 47, 32)       2080        spatial_dropout1d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 47, 32)       128         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 47, 32)       0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, 47, 32)       0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 47, 32)       2080        spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 47, 32)       0           add_17[0][0]                     \n",
      "                                                                 conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 47, 32)       6272        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 47, 16)       528         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 47, 16)       64          conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 47, 32)       4224        batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 47, 16)       528         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 47, 16)       64          conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attentionD0 (SeqSelfAttention)  [(None, 47, 16), (No 1089        batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 47, 16)       0           batch_normalization_32[0][0]     \n",
      "                                                                 attentionD0[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 47, 16)       32          add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "feed_forward_3 (FeedForward)    (None, 47, 16)       4240        layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 47, 16)       0           layer_normalization_5[0][0]      \n",
      "                                                                 feed_forward_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 47, 16)       32          add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attentionD (SeqSelfAttention)   [(None, 47, 16), (No 1089        layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 47, 16)       0           layer_normalization_6[0][0]      \n",
      "                                                                 attentionD[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 47, 16)       32          add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "feed_forward_4 (FeedForward)    (None, 47, 16)       4240        layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 47, 16)       0           layer_normalization_7[0][0]      \n",
      "                                                                 feed_forward_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 47, 16)       32          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 47, 16)       2112        layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 47, 16)       2112        layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attentionP (SeqSelfAttention)   [(None, 47, 16), (No 1089        lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attentionS (SeqSelfAttention)   [(None, 47, 16), (No 1089        lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_22 (UpSampling1D) (None, 94, 16)       0           layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_29 (UpSampling1D) (None, 94, 16)       0           attentionP[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_36 (UpSampling1D) (None, 94, 16)       0           attentionS[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_36 (SeparableC (None, 94, 32)       592         up_sampling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_43 (SeparableC (None, 94, 32)       592         up_sampling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_50 (SeparableC (None, 94, 32)       592         up_sampling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_23 (UpSampling1D) (None, 188, 32)      0           separable_conv1d_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_30 (UpSampling1D) (None, 188, 32)      0           separable_conv1d_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_37 (UpSampling1D) (None, 188, 32)      0           separable_conv1d_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_37 (SeparableC (None, 188, 64)      2272        up_sampling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_44 (SeparableC (None, 188, 64)      2272        up_sampling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_51 (SeparableC (None, 188, 64)      2272        up_sampling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_24 (UpSampling1D) (None, 376, 64)      0           separable_conv1d_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_31 (UpSampling1D) (None, 376, 64)      0           separable_conv1d_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_38 (UpSampling1D) (None, 376, 64)      0           separable_conv1d_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_38 (SeparableC (None, 376, 32)      2400        up_sampling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_45 (SeparableC (None, 376, 32)      2400        up_sampling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_52 (SeparableC (None, 376, 32)      2400        up_sampling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_25 (UpSampling1D) (None, 752, 32)      0           separable_conv1d_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_32 (UpSampling1D) (None, 752, 32)      0           separable_conv1d_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_39 (UpSampling1D) (None, 752, 32)      0           separable_conv1d_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d_4 (Cropping1D)       (None, 750, 32)      0           up_sampling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d_5 (Cropping1D)       (None, 750, 32)      0           up_sampling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "cropping1d_6 (Cropping1D)       (None, 750, 32)      0           up_sampling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_39 (SeparableC (None, 750, 32)      1280        cropping1d_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_46 (SeparableC (None, 750, 32)      1280        cropping1d_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_53 (SeparableC (None, 750, 32)      1280        cropping1d_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_26 (UpSampling1D) (None, 1500, 32)     0           separable_conv1d_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_33 (UpSampling1D) (None, 1500, 32)     0           separable_conv1d_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_40 (UpSampling1D) (None, 1500, 32)     0           separable_conv1d_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_40 (SeparableC (None, 1500, 16)     752         up_sampling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_47 (SeparableC (None, 1500, 16)     752         up_sampling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_54 (SeparableC (None, 1500, 16)     752         up_sampling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_27 (UpSampling1D) (None, 3000, 16)     0           separable_conv1d_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_34 (UpSampling1D) (None, 3000, 16)     0           separable_conv1d_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_41 (UpSampling1D) (None, 3000, 16)     0           separable_conv1d_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_41 (SeparableC (None, 3000, 16)     416         up_sampling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_48 (SeparableC (None, 3000, 16)     416         up_sampling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_55 (SeparableC (None, 3000, 16)     416         up_sampling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_28 (UpSampling1D) (None, 6000, 16)     0           separable_conv1d_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_35 (UpSampling1D) (None, 6000, 16)     0           separable_conv1d_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_42 (UpSampling1D) (None, 6000, 16)     0           separable_conv1d_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_42 (SeparableC (None, 6000, 8)      312         up_sampling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_49 (SeparableC (None, 6000, 8)      312         up_sampling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv1d_56 (SeparableC (None, 6000, 8)      312         up_sampling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "detector (Conv1D)               (None, 6000, 1)      89          separable_conv1d_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "picker_P (Conv1D)               (None, 6000, 1)      89          separable_conv1d_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "picker_S (Conv1D)               (None, 6000, 1)      89          separable_conv1d_56[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 101,440\n",
      "Trainable params: 100,480\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n",
      "Started training in generator mode ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 3832s 639ms/step - loss: 0.0174 - detector_loss: 0.0835 - picker_P_loss: 0.0146 - picker_S_loss: 0.0126 - detector_f1: 0.7196 - picker_P_f1: 0.0082 - picker_S_f1: 0.0000e+00 - val_loss: 0.0051 - val_detector_loss: 0.0227 - val_picker_P_loss: 0.0041 - val_picker_S_loss: 0.0044 - val_detector_f1: 0.9220 - val_picker_P_f1: 0.1708 - val_picker_S_f1: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00512, saving model to C:\\Users\\JeoungSeoungHeong\\EQ\\EQTransformer_master\\test_trainer_outputs\\models\\test_trainer_001.h5\n",
      "Epoch 2/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 3960s 660ms/step - loss: 0.0078 - detector_loss: 0.0385 - picker_P_loss: 0.0060 - picker_S_loss: 0.0061 - detector_f1: 0.8826 - picker_P_f1: 0.2389 - picker_S_f1: 0.0728 - val_loss: 0.0044 - val_detector_loss: 0.0131 - val_picker_P_loss: 0.0030 - val_picker_S_loss: 0.0038 - val_detector_f1: 0.9538 - val_picker_P_f1: 0.5233 - val_picker_S_f1: 0.2687\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00512 to 0.00445, saving model to C:\\Users\\JeoungSeoungHeong\\EQ\\EQTransformer_master\\test_trainer_outputs\\models\\test_trainer_002.h5\n",
      "Epoch 3/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 4401s 734ms/step - loss: 0.0070 - detector_loss: 0.0322 - picker_P_loss: 0.0054 - picker_S_loss: 0.0056 - detector_f1: 0.9002 - picker_P_f1: 0.3551 - picker_S_f1: 0.1847 - val_loss: 0.0044 - val_detector_loss: 0.0140 - val_picker_P_loss: 0.0027 - val_picker_S_loss: 0.0038 - val_detector_f1: 0.9573 - val_picker_P_f1: 0.5917 - val_picker_S_f1: 0.2830\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00445 to 0.00437, saving model to C:\\Users\\JeoungSeoungHeong\\EQ\\EQTransformer_master\\test_trainer_outputs\\models\\test_trainer_003.h5\n",
      "Epoch 4/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 4258s 710ms/step - loss: 0.0066 - detector_loss: 0.0294 - picker_P_loss: 0.0051 - picker_S_loss: 0.0053 - detector_f1: 0.9094 - picker_P_f1: 0.3969 - picker_S_f1: 0.2412 - val_loss: 0.0038 - val_detector_loss: 0.0119 - val_picker_P_loss: 0.0024 - val_picker_S_loss: 0.0036 - val_detector_f1: 0.9610 - val_picker_P_f1: 0.6366 - val_picker_S_f1: 0.3088\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00437 to 0.00381, saving model to C:\\Users\\JeoungSeoungHeong\\EQ\\EQTransformer_master\\test_trainer_outputs\\models\\test_trainer_004.h5\n",
      "Epoch 5/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 4554s 759ms/step - loss: 0.0063 - detector_loss: 0.0276 - picker_P_loss: 0.0049 - picker_S_loss: 0.0052 - detector_f1: 0.9153 - picker_P_f1: 0.4282 - picker_S_f1: 0.2727 - val_loss: 0.0046 - val_detector_loss: 0.0125 - val_picker_P_loss: 0.0023 - val_picker_S_loss: 0.0036 - val_detector_f1: 0.9618 - val_picker_P_f1: 0.6531 - val_picker_S_f1: 0.3729\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00381\n",
      "Epoch 6/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 4528s 755ms/step - loss: 0.0062 - detector_loss: 0.0268 - picker_P_loss: 0.0049 - picker_S_loss: 0.0051 - detector_f1: 0.9170 - picker_P_f1: 0.4409 - picker_S_f1: 0.2935 - val_loss: 0.0042 - val_detector_loss: 0.0104 - val_picker_P_loss: 0.0023 - val_picker_S_loss: 0.0035 - val_detector_f1: 0.9658 - val_picker_P_f1: 0.6639 - val_picker_S_f1: 0.3945\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00381\n",
      "Epoch 7/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 4110s 685ms/step - loss: 0.0060 - detector_loss: 0.0256 - picker_P_loss: 0.0047 - picker_S_loss: 0.0050 - detector_f1: 0.9209 - picker_P_f1: 0.4538 - picker_S_f1: 0.3060 - val_loss: 0.0030 - val_detector_loss: 0.0089 - val_picker_P_loss: 0.0021 - val_picker_S_loss: 0.0034 - val_detector_f1: 0.9676 - val_picker_P_f1: 0.6611 - val_picker_S_f1: 0.3440\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00381 to 0.00298, saving model to C:\\Users\\JeoungSeoungHeong\\EQ\\EQTransformer_master\\test_trainer_outputs\\models\\test_trainer_007.h5\n",
      "Epoch 8/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 3749s 625ms/step - loss: 0.0059 - detector_loss: 0.0247 - picker_P_loss: 0.0047 - picker_S_loss: 0.0050 - detector_f1: 0.9237 - picker_P_f1: 0.4628 - picker_S_f1: 0.3221 - val_loss: 0.0033 - val_detector_loss: 0.0093 - val_picker_P_loss: 0.0020 - val_picker_S_loss: 0.0033 - val_detector_f1: 0.9671 - val_picker_P_f1: 0.6922 - val_picker_S_f1: 0.4073\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00298\n",
      "Epoch 9/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 3857s 643ms/step - loss: 0.0058 - detector_loss: 0.0236 - picker_P_loss: 0.0046 - picker_S_loss: 0.0049 - detector_f1: 0.9256 - picker_P_f1: 0.4712 - picker_S_f1: 0.3348 - val_loss: 0.0030 - val_detector_loss: 0.0095 - val_picker_P_loss: 0.0021 - val_picker_S_loss: 0.0034 - val_detector_f1: 0.9651 - val_picker_P_f1: 0.6666 - val_picker_S_f1: 0.3863\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00298\n",
      "Epoch 10/10\n",
      "Learning rate:  0.001\n",
      "6000/6000 [==============================] - 3911s 652ms/step - loss: 0.0057 - detector_loss: 0.0231 - picker_P_loss: 0.0045 - picker_S_loss: 0.0048 - detector_f1: 0.9289 - picker_P_f1: 0.4788 - picker_S_f1: 0.3460 - val_loss: 0.0029 - val_detector_loss: 0.0085 - val_picker_P_loss: 0.0020 - val_picker_S_loss: 0.0033 - val_detector_f1: 0.9706 - val_picker_P_f1: 0.6936 - val_picker_S_f1: 0.4103\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00298 to 0.00295, saving model to C:\\Users\\JeoungSeoungHeong\\EQ\\EQTransformer_master\\test_trainer_outputs\\models\\test_trainer_010.h5\n"
     ]
    }
   ],
   "source": [
    "user_trainer(input_hdf5='mix_train_merge_modified.hdf5',\n",
    "        input_csv='mix_train_merge_modified.csv',\n",
    "        output_name='test_trainer',                \n",
    "        cnn_blocks=5,\n",
    "        lstm_blocks=2,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        drop_rate=0.2,\n",
    "        label_type='gaussian',\n",
    "        add_event_r=0.6,\n",
    "        add_gap_r=0.2,\n",
    "        shift_event_r=0.9,\n",
    "        add_noise_r=0.5, \n",
    "        mode='generator',\n",
    "        train_valid_test_split=[0.60, 0.20, 0.20],\n",
    "        batch_size=20,\n",
    "        epochs=10, \n",
    "        patience=10,\n",
    "        gpuid=None,\n",
    "        gpu_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cad9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from EQTransformer.core.mytester import tester\n",
    "tester(input_hdf5='mix_train_merge_modified.hdf5',\n",
    "       input_testset='test_trainer_outputs/test.npy',\n",
    "       input_model='test_trainer_outputs/final_model.h5',\n",
    "       output_name='test_tester',\n",
    "       detection_threshold=0.20,                \n",
    "       P_threshold=0.1,\n",
    "       S_threshold=0.1, \n",
    "       number_of_plots=3,\n",
    "       estimate_uncertainty=True, \n",
    "       number_of_sampling=2,\n",
    "       input_dimention=(6000, 3),\n",
    "       normalization_mode='std',\n",
    "       mode='generator',\n",
    "       batch_size=10,\n",
    "       gpuid=None,\n",
    "       gpu_limit=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e7e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
